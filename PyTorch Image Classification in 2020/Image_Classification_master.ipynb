{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification_master.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkSTDPVCKSPlfdYBRM/glF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranjalchaubey/Deep-Learning-Notes/blob/master/PyTorch%20Image%20Classification%20in%202020/Image_Classification_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut1uDoXJzCTu",
        "colab_type": "text"
      },
      "source": [
        "# Image Classification using PyTorch in 2020  \n",
        "\n",
        "In this notebook we will be utilizing some of the latest advancements in the  \n",
        "[PyTorch Ecosystem](https://pytorch.org/ecosystem/) to build a simple image classifier using CNNs.   \n",
        "\n",
        "Along the way, we will learn some PyTorch and CNN (Convolution Neural  \n",
        "Networks) basics. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFhLAYud0CQK",
        "colab_type": "text"
      },
      "source": [
        "### 1. Get the Dataset Onboard\n",
        "\n",
        "In any Machine Learning/Data Science problem, the first step is always to get  \n",
        "the dataset.  \n",
        "\n",
        "In our case, to get things started, we will initially use the simple [MNIST Dataset](https://en.wikipedia.org/wiki/MNIST_database).  \n",
        "MNIST is largely considered the _'Hello World!'_ of AI/ML. The dataset was  \n",
        "created way back in the late 90s. The [official description](http://yann.lecun.com/exdb/mnist/) states,  \n",
        "\n",
        "_\"The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image._  \n",
        "\n",
        "_It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\"_  \n",
        "\n",
        "<br/>You might be wondering, how to get this dataset in our Colab Workspace?  \n",
        "PyTorch comes with a _datasets_ module called, [Torchvision.Datasets](https://pytorch.org/docs/stable/torchvision/datasets.html).  \n",
        "Torchvision.Datasets module contains a number of publically available datasets  \n",
        "including the one we are looking for, MNIST. You are encouraged to explore the  \n",
        "Torchvision.Datasets documentation page. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tia9JXE46rJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets import some libraries \n",
        "import torch # PyTorch \n",
        "from torchvision import datasets # Datasets module \n",
        "import torchvision.transforms as transforms # Image Transforms \n",
        "from torch.utils.data.sampler import SubsetRandomSampler # Sampler "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVP4itgp7jC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Data Science Regulars\n",
        "import numpy as np \n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h8vdeaZ7sj_",
        "colab_type": "text"
      },
      "source": [
        "Checking out the torchvision.datasets module documentation, we find  \n",
        "![Torchvision.Dataset](https://drive.google.com/uc?id=1Zsgc5_PnO9BQQ5wqssf67A5Ge-qIXtLh)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UapF3_qS67Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = datasets.MNIST(root='data', train=True,    # train=true => training set \n",
        "                                   download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False,    # train=false => test set \n",
        "                                  download=True, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnZrOAcMZRTp",
        "colab_type": "text"
      },
      "source": [
        "### 2. Train Validation Test Split \n",
        "\n",
        "Once the download is complete (usually instantaneous), you should be able to  \n",
        "see the MNIST dataset downloaded inside the _'data'_ folder on the left hand  \n",
        "side. (Click on the _Files_ icon on the left sidebar)  \n",
        "\n",
        "We have both the training and the test sets. Now we need to bifurcate the   \n",
        "training set in two parts,  \n",
        "1. Training Set (80% images)\n",
        "2. Validation Set (20% images)  \n",
        "\n",
        "The algorithm we use to do this is quite simple,  \n",
        "1. Create a list of indices of the training data \n",
        "2. Randomly Shuffle those indices \n",
        "3. Slice the indices in 80-20 split \n",
        "\n",
        "[Why create a _Validation Set_ at all?](https://datascience.stackexchange.com/questions/18339/why-use-both-validation-set-and-test-set) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrsPBIfRYwNc",
        "colab_type": "code",
        "outputId": "c49cfeb8-4b15-4f79-f316-f4c6873408d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# obtain training indices that will be used for validation\n",
        "\n",
        "# 1. Create a list of indices of the training data  \n",
        "num_train = len(train_data)\n",
        "print('num_train = len(train_data) ==> ', num_train)\n",
        "indices = list(range(num_train))\n",
        "print('len(indices) ==>', len(indices))\n",
        "# print(indices)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_train = len(train_data) ==>  60000\n",
            "len(indices) ==> 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjDu_dd35TZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. Randomly Shuffle those indices\n",
        "np.random.shuffle(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKqrNSg-5VMq",
        "colab_type": "code",
        "outputId": "690fe3f9-6996-4118-bd85-2b1479b8e8b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 3. Slice the indices in 80-20 split\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2 # ie Train Set divided into two parts \n",
        "                 # 80% Train 20% Validation \n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "print('len(train_idx) ==> ', len(train_idx))\n",
        "print('len(valid_idx) ==> ', len(valid_idx))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(train_idx) ==>  48000\n",
            "len(valid_idx) ==>  12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14RHH0Jt8_k_",
        "colab_type": "text"
      },
      "source": [
        "Please Note that so far we have just been fiddling around with the _'indices'_,  \n",
        "not the actual images as such.....but Why?  \n",
        "Answer below.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlTpuhxVAfCK",
        "colab_type": "text"
      },
      "source": [
        "### 3. Prepare the Dataloaders \n",
        "\n",
        "By now, we have downloaded the dataset, and created a train/valid/test split.  \n",
        "Q: How do we _'push'_ this data into a PyTorch model?  \n",
        "A: PyTorch has a mechanism to _'ingest'_ data from a dataset through a module  \n",
        "known as `DataLoader`.  \n",
        "\n",
        "A great analogy,  \n",
        "![DataLoader](https://drive.google.com/uc?id=1U4IG-5lbFGQQS4xwQPU2QiYdR1hFGBZ5)\n",
        "\n",
        "[Great tutorial on DataLoaders.](https://www.journaldev.com/36576/pytorch-dataloader)  \n",
        "[Ultimate tutorial on DataLoaders.](https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel) \n",
        "\n",
        "Time to prepare the _DataLoaders_ now!  \n",
        "\n",
        "![DataLoader Documentation](https://drive.google.com/uc?id=1YFbWIGwNlL5Kp4Zvt52Ck0_Wk4MNfxS9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Zzb55d8k7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define samplers for obtaining training and validation batches\n",
        "# remember train_idx and valid_idx were the indices that we shuffled above\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare dataloaders\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0 # do not modify \n",
        "# how many samples per batch to load\n",
        "batch_size = 20 # ie 20 images per batch \n",
        "\n",
        "# Training Set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, \\\n",
        "                                           batch_size=batch_size, \\\n",
        "                                           sampler=train_sampler, \\\n",
        "                                           num_workers=num_workers)\n",
        "# Validation Set \n",
        "valid_loader = torch.utils.data.DataLoader(dataset=train_data, \\\n",
        "                                           batch_size=batch_size, \\\n",
        "                                           sampler=valid_sampler, \\\n",
        "                                           num_workers=num_workers)\n",
        "# Test Set \n",
        "# Notice we have not used a 'sampler' here as it was not required \n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, \\\n",
        "                                          batch_size=batch_size, \\\n",
        "                                          num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBy_7mS_4hdc",
        "colab_type": "text"
      },
      "source": [
        "We got the dataloaders working, but how do we know that they are working indeed?  \n",
        "Visualizing the data from the dataloaders would be a good check! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrRjUiQG5uOu",
        "colab_type": "code",
        "outputId": "837649ad-f09e-47af-91ad-f1084f46a1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Visualize a whole batch of data from the dataloaders \n",
        "\n",
        "dataiter = iter(train_loader) # Get the whole batch \n",
        "images, labels = dataiter.next() # Extract the images and their labels \n",
        "print(len(images), len(labels)) # Should be equal to the batch size, 20\n",
        "print('Correct Labels: ', labels)\n",
        "images = images.numpy() # Convert the images to numpy array for matplotlib\n",
        "print('Shape of our images tensor =', images.shape)\n",
        "print('Batch Size =', images.shape[0], 'Image Height/Width =', \\\n",
        "                                                        images.shape[2])\n",
        "\n",
        "print()\n",
        "print('Squeezing the images tensor =', np.squeeze(images).shape)\n",
        "print('Un-squeezing the images tensor (axis=3) =', \\\n",
        "                                        np.expand_dims(images, axis=3).shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 20\n",
            "Correct Labels:  tensor([4, 6, 1, 6, 4, 7, 3, 3, 7, 2, 7, 6, 9, 2, 8, 5, 9, 6, 6, 3])\n",
            "Shape of our images tensor = (20, 1, 28, 28)\n",
            "Batch Size = 20 Image Height/Width = 28\n",
            "\n",
            "Squeezing the images tensor = (20, 28, 28)\n",
            "Un-squeezing the images tensor (axis=3) = (20, 1, 28, 1, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y58P0-etIck4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "# Plots are plotted inside the notebooks, 'inline'\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL8sSrheGg9-",
        "colab_type": "text"
      },
      "source": [
        "With matplotlib, always remember that _figures contain axes which in turn   \n",
        "contain the plots_.  \n",
        "![Real Python](https://drive.google.com/uc?id=1KdlAGoCK8Lj9pFkrZf52oqOJK3sH3JuH)  \n",
        "\n",
        "[Great tutorial on Matplotlib.](https://realpython.com/python-matplotlib-guide/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC5KTKSv6Y8T",
        "colab_type": "code",
        "outputId": "f2507dc5-c26a-409d-c8e5-d222f723c3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# Plot the whole batch \n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "# Loop over all the images in the batch(20)\n",
        "for idx in np.arange(20):\n",
        "    # Add a subplot for the image \n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    # Populate the subplot with the image \n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    # print out the correct label for each image\n",
        "    # .item() gets the value contained in a Tensor\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABXEAAAD7CAYAAAAsAtcsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEGMRFwAAAAAAAABC7P8BYxR1aRPHgKgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls_AFh0FzMkG",
        "colab_type": "code",
        "outputId": "0c9d1746-7706-4e55-fd1d-2c96a3d135af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# A neat little numpy trick\n",
        "# Just for fun! \n",
        "\n",
        "dataiter = iter(train_loader)  \n",
        "images, labels = dataiter.next() \n",
        "images = images.numpy() \n",
        "np.set_printoptions(precision=2, threshold=None, edgeitems=None, \\\n",
        "                    linewidth=180, suppress=None)\n",
        "print('Label', labels[0])\n",
        "print(images[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label tensor(8)\n",
            "[[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.26 0.58 0.65 0.9  1.   1.   0.78 0.38 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.16 0.47 0.91 0.98 0.99 0.97 0.72 0.72 0.72 0.89 0.98 0.52 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.9  0.99 0.95 0.58 0.38 0.06 0.   0.   0.   0.14 0.79 0.98 0.21 0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.93 0.99 0.2  0.   0.   0.   0.   0.   0.   0.   0.03 0.64 0.6  0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.69 0.99 0.52 0.03 0.   0.   0.   0.12 0.06 0.   0.   0.03 0.07 0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.04 0.67 0.97 0.8  0.33 0.16 0.73 0.89 0.3  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.36 0.91 0.99 0.99 0.98 0.27 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.24 0.89 0.94 0.93 0.99 0.83 0.31 0.03 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.22 0.91 0.93 0.13 0.02 0.52 0.85 1.   0.73 0.18 0.02 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.09 0.93 0.99 0.27 0.   0.   0.   0.   0.42 0.86 0.99 0.75 0.17 0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.57 1.   0.25 0.   0.   0.   0.   0.   0.   0.   0.41 0.96 0.93 0.22 0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.93 0.86 0.05 0.   0.   0.   0.   0.   0.   0.   0.   0.29 0.95 0.93 0.44 0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.93 0.78 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.24 0.81 0.98 0.31 0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.93 0.78 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.29 0.99 0.58 0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.93 0.89 0.07 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.32 0.99 0.58 0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.44 0.98 0.35 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.53 0.99 0.58 0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.74 0.96 0.21 0.   0.   0.   0.   0.   0.   0.   0.09 0.58 0.96 0.91 0.2  0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.2  0.94 0.96 0.49 0.15 0.07 0.07 0.07 0.29 0.61 0.97 0.99 0.91 0.32 0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.3  0.78 0.98 0.99 0.99 0.99 1.   0.99 0.97 0.76 0.44 0.14 0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.59 0.99 0.75 0.65 0.44 0.13 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2APl70a5LH66",
        "colab_type": "text"
      },
      "source": [
        "Our dataloaders seem to be working fine and out data looks great!  \n",
        "<br/> \n",
        "Time to build our CNN based image classification model in PyTorch.....in 2020! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGFnKhH5Lh9t",
        "colab_type": "text"
      },
      "source": [
        "### 4. Build a PyTorch CNN Model\n",
        "But first, we need to know how CNNs work and what are the components of a  \n",
        "typical CNN based image classification architecture.  \n",
        "\n",
        "![CNN Scan](https://media.giphy.com/media/vRINohj6YtmnkTQqHi/giphy.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e99lxoYpt9o8",
        "colab_type": "text"
      },
      "source": [
        "####4.1.1 CNN Architecture  \n",
        "A typical CNN Architecture looks like this,  \n",
        "\n",
        "![Block CNN Architecture](https://drive.google.com/uc?id=1RYYh27hsyY5Mx4L_lwGUVGQ3OYkSCqB- \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\")  \n",
        "<br/>A real life example of VGG-16,  \n",
        "\n",
        "![VGG-16 Architecture](https://drive.google.com/uc?id=14OYg0ihFKHGsLQLcqoeSLt2nyPS4quss \"https://www.researchgate.net/figure/The-architecture-of-a-VGG-16-network_fig2_330467052\")  \n",
        "<br/>Another example, very close to what we are going to build today,  \n",
        "\n",
        "![MNIST CNN Architecture](https://drive.google.com/uc?id=1cnDzorKeRmNUAUJYw2yvQiY2D4f-sDNL \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obnRoku91VXj",
        "colab_type": "text"
      },
      "source": [
        "####4.1.2 Basic CNN Layer  \n",
        "So how does a CNN layer actually _'works'_?  \n",
        "\n",
        "![CNN Scan](https://drive.google.com/uc?id=1JictobCPmaIX_9pm2mQewc4QiAzl0pzO \"Remember Billie Eilish above?\")  \n",
        "\n",
        "<br/>A colored image has 3 channels,  \n",
        "![RGB Image](https://drive.google.com/uc?id=1QlU04TZ6IN2IRqQJFB8m6GFJ2MmqYGhz \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\")  \n",
        "\n",
        "<br/>A 3-channel convolution,  \n",
        "![RGB Convolution](https://drive.google.com/uc?id=1CGIqxGHjJGXr8aduPtwGd1-ikgA3WqJ5 \"https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\")  \n",
        "\n",
        "![RGB Convolution Summation](https://drive.google.com/uc?id=1fpM3NLvyjeiKF6_at0Nv4XhYPRkwH1IY \"https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsM9p5pN55Ht",
        "colab_type": "text"
      },
      "source": [
        "####4.1.3 Stride  \n",
        "_'Stride'_ of the kernel while scanning the image.  \n",
        "\n",
        "Here's an example with _stride=1_,  \n",
        "![CNN Stride = 1](https://drive.google.com/uc?id=1wJd7VCYfiMDes0Ex0SlBL97yBP6P7ajt \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\")  \n",
        "\n",
        "<br/>Another example with _stride=2_,  \n",
        "![CNN Stride = 2](https://drive.google.com/uc?id=1dG2i4WtxUzu9Wlsl3jyH4ZXxUSYVdKfk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0UTagwYo92ZK"
      },
      "source": [
        "####4.1.4 Padding  \n",
        "Padding ensures that there is no loss of information while an image with a  \n",
        "convolutional kernel.  \n",
        "![Padding = 1](https://drive.google.com/uc?id=1xIQSJVRtAS7em_E387ZBd6sErjwA7RD6 \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kKK72-_H94bi"
      },
      "source": [
        "####4.1.5 Max Pooling  \n",
        "Max Pooling layer primarily reduces the dimensionality of the input.  \n",
        "\n",
        "![Max Pooling](https://drive.google.com/uc?id=11_1ThNaU4e4DAEFs7I9GsNoD7oFmtVES \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\")  \n",
        "\n",
        "Max Pooling is not the only type of pooling layer out there.  \n",
        "![Type of Pooling](https://drive.google.com/uc?id=1ECZrE8vAhTE1gEsp_3vPy03oLuSj0aOW)  \n",
        "\n",
        "[A nice tutorial on pooling layers.](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/ \"Json Brownlee is an absolute genius. His blog is a damn goldmine!\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98q9buSu-hxw",
        "colab_type": "text"
      },
      "source": [
        "####4.1.6 Rectified Linear Units aka ReLU  \n",
        "The non-linear activation function.  \n",
        "![ReLU Activation](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png \"https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvnlvaIQ_ECZ",
        "colab_type": "text"
      },
      "source": [
        "####4.1.7 _Fully Connected_ or _Linear Layers_  \n",
        "Final dimensionality reduction for either classification or regression tasks.  \n",
        "\n",
        "![Fully Connected Layers](https://drive.google.com/uc?id=1Fwh-NqMDLx-xqKlqN2c-z780M9aBUHvO \"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xct_yN3R_8pP",
        "colab_type": "text"
      },
      "source": [
        "Before we move forward, a few questions for everyone:  \n",
        "1. What kind of features do the first few CNN layers capture?  \n",
        "2. What kind of features do the last few CNN layers capture? \n",
        "3. What is the role of max-pool?  \n",
        "4. Can we use _stride_ to perform a role similar to max-pool?  \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el1NUdaz0HrE",
        "colab_type": "text"
      },
      "source": [
        "####4.2.1 PyTorch  \n",
        "PyTorch is currently the hottest Deep Learning library out there. In terms of  \n",
        "popularity, it has even taken over Tensorflow. Tensorflow came before PyTorch  \n",
        "and is backed by the engineering and marketing might of _**Google**_.  \n",
        "\n",
        "_Why PyTorch got so darn famous?_  \n",
        "The answer lies in the fact that PyTorch is highly pythonic (due to dynamic  \n",
        "computational graphs) which makes it extremely flexible and ideal for  \n",
        "researchers and developers alike.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iKCm6RQJUL5",
        "colab_type": "text"
      },
      "source": [
        "####4.2.2 Understanding Computational Graphs   \n",
        "At the bottom of every Deep Neural Network training, there are only two things  \n",
        "taking place, \n",
        "1. A forward pass - pushing images/data from the start of the network and   \n",
        "generating an output (and a loss/error).  \n",
        "2. Backpropagation - essentially a backward pass where we calculate gradients  \n",
        "using partial derivatives with respect to the loss, and make changes to the  \n",
        "weights of the network. In a nutshell, this is how deep learning networks  \n",
        "train.  \n",
        "\n",
        "![A Computational Graph](https://drive.google.com/uc?id=1dgVg08M02gfIkPm0JKyhm4k4gYVLB_Me \"Udacity Deep Learning Nano Degree\")  \n",
        "The image above, is a simple neural network. But it is also a   \n",
        "computational graph.  \n",
        "\n",
        "We first make a forward pass through our network and then a backward pass  \n",
        "to calculate how much loss was being contributed by _**W1**_ weight in  \n",
        "particular.  \n",
        "\n",
        "Every neural network you define, PyTorch _sees_ it as a computational graph  \n",
        "similar to what we see above and keeps a track of all the operations   \n",
        "performed by every node. This ensures that it calculates accurate gradients  \n",
        "when make a backward pass.  \n",
        "\n",
        "Good thing about PyTorch is that it creates these computational graphs on the  \n",
        "fly! And this aspect makes PyTorch and extremely felxible (and pythonic) deep  \n",
        "learning library.   \n",
        "\n",
        "![Dynamic Computational Graphs](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/09/dynamic_graph.gif \"PyTorch building dynamic computational graphs on the fly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNCoUgD7R-wL",
        "colab_type": "text"
      },
      "source": [
        "####4.2.3 Tensors  \n",
        "Tensors are the building blocks of every deep learning library including   \n",
        "PyTorch. What are tensors though?  \n",
        "\n",
        "![Tensors](https://drive.google.com/uc?id=1F5cLclu4RML7zj7axf8IGU7aUXJlI7N0 \"Udacity Deep Learning Nano Degree\")  \n",
        "\n",
        "Creating tensors in PyTorch is easy  \n",
        "```\n",
        "import torch \n",
        "x = torch.rand(3, 3)\n",
        "print(x)\n",
        "\n",
        ">>Prints out:\n",
        ">>tensor([[0.5264, 0.1839, 0.9907],\n",
        ">>        [0.0343, 0.9839, 0.9294],\n",
        ">>        [0.6938, 0.6755, 0.2258]])\n",
        "```\n",
        "Tensors in PyTorch are exactly like the numpy arrays, except that they can   \n",
        "also live on a GPU which makes them realy really fast!  \n",
        "```\n",
        "torch.FloatTensor([[20, 30, 40], [90, 60, 70]]) # Tensor on CPU\n",
        "torch.cuda.FloatTensor([[20, 30, 40], [90, 60, 70]]) # Tensor on GPU\n",
        "```\n",
        "Moving tensors (and complex deep learning models) to a GPU (or a CPU) is   \n",
        "pretty straightforward in PyTorch. \n",
        "```\n",
        "x = torch.FloatTensor([[20, 30, 40], [90, 60, 70]]) # Tensor on CPU\n",
        "print('Is tensor x on GPU?', x.is_cuda) # False\n",
        "x = x.to('cuda') # Moves to GPU\n",
        "print('Is tensor x on GPU?', x.is_cuda) # True \n",
        "x = x.to('cpu') # Moves back to CPU\n",
        "print('Is tensor x on GPU?', x.is_cuda) # False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0VnwmbZVrLW",
        "colab_type": "text"
      },
      "source": [
        "####4.2.4 The Autograd Module  \n",
        "Autograd is the real rockstar module in PyTorch.  \n",
        "Autograd is the module that keeps a track of all the operations performed on a  \n",
        "tensor and calculates the gradients through a technique called _**Automatic  \n",
        "Differentiation**_  \n",
        "\n",
        "To enable tracking computation history on a tensor, set _**`.requires_grad`**_  \n",
        "to _**`True`**_. To detach a tensor from its computation history, call   \n",
        "_**`.detach()`**_.  \n",
        "\n",
        "In order to stop autograd from keeping history of computations on a deep  \n",
        "learning model, wrap it around _**`torch.no_grad():`**_. This is usually done  \n",
        "during inference. \n",
        "```\n",
        "with torch.no_grad():\n",
        "    # inference code \n",
        "``` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S0uLBsCZqjG",
        "colab_type": "text"
      },
      "source": [
        "####4.2.5 The nn.Module  \n",
        "The nn module in PyTorch is used to 'build' the neural networks and contains  \n",
        "all the deep learning layers. It obviously depends upon the autograd module to  \n",
        "calculate gradients.  \n",
        "\n",
        "When defining our custom models in PyTorch, we typically subclass the   \n",
        "nn.Module class and override the `__init__()` and `forward()` functions.  \n",
        "1. `__init__()` - This is where we define the layers of our network. \n",
        "2. `forward()` - This is where you actaully connect the layers together and  \n",
        "make everything work.  \n",
        "\n",
        "Don't worry if this sounds a little confusing, we will be seeing `nn.Module`   \n",
        "in action very soon! \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0MkS6OadYRQ",
        "colab_type": "text"
      },
      "source": [
        "####4.2.6 The Optim Package  \n",
        "The optim package in PyTorch contains the optimization algorithms that help   \n",
        "to train your network.  \n",
        "\n",
        "A simple example,  \n",
        "`optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)`  \n",
        "\n",
        "<br/>[My all time favorite 'Intro to PyTorch' tutorial](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e \"Understanding PyTorch with an example: a step-by-step tutorial\")  \n",
        "[Great PyTorch Tutorial Part 1](https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/ \"PyTorch 101, Part 1: Understanding Graphs, Automatic Differentiation and Autograd\")  \n",
        "[Great PyTorch Tutorial Part 2](https://blog.paperspace.com/pytorch-101-building-neural-networks/ \"PyTorch 101, Part 2: Building Your First Neural Network\")  \n",
        "[Great PyTorch Tutorial Part 3](https://blog.paperspace.com/pytorch-101-advanced/ \"PyTorch 101, Part 3: Going Deep with PyTorch\")  \n",
        "[Great PyTorch Tutorial Part 4](https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/ \"PyTorch 101, Part 4: Memory Management and Using Multiple GPUs\")  \n",
        "[Great PyTorch Tutorial Part 5](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/ \"PyTorch 101, Part 5: Understanding Hooks\")  \n",
        "[Stunning Insight into the Internals of PyTorch](http://blog.ezyang.com/2019/05/pytorch-internals/ \"PyTorch Internals\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYblCGur448H",
        "colab_type": "text"
      },
      "source": [
        "####4.3 Time to define our model!  \n",
        "But before we start off with the model definition, let's have a look at what  \n",
        "the PyTorch Documentation says about the Convolutional NNs.  \n",
        "\n",
        "![Conv2d Layer](https://drive.google.com/uc?id=1odHZIXURYjogjUcyCQ56RYfQPqgzO7DX \"Conv2D\")  \n",
        "\n",
        "<br/>We also need to check out about the MaxPool, Dropout and Linear Layers.  \n",
        "\n",
        "![MaxPool 2D](https://drive.google.com/uc?id=1r1EeLHrV5oAG4OUyRSm0lw2OcZyJQ7ne \"MaxPool2D Layer\")  \n",
        "\n",
        "![Dropout Layer](https://drive.google.com/uc?id=1kYgb4wDrGEBEF5WB169N7Q5hTrwDDO1d \"Dropout Layer\")  \n",
        "\n",
        "![Linear Layer](https://drive.google.com/uc?id=1rrIEqPtun_8Td1js76B2hv22Xm5tjY6m \"Linear Layer\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0zv4wi7BNRL",
        "colab_type": "text"
      },
      "source": [
        "Did you guys notice a weird anomaly in the Conv2d and Linear layers?  \n",
        "```\n",
        "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "```  \n",
        "```\n",
        "torch.nn.Linear(in_features, out_features, bias=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrhOYd8JTQ-B",
        "colab_type": "text"
      },
      "source": [
        "Conv2d layer expects `in_channels` while the Linear layer expects `in_features`.  \n",
        "\n",
        "Bottom line is, that PyTorch expects different things from a tensor dimension.  \n",
        "Specifically,  \n",
        "```\n",
        "\"\"\"Example tensor size outputs, how PyTorch reads them, and where you encounter them in the wild. \n",
        "Note: the values below are only examples. Focus on the rank of the tensor (how many dimensions it has).\"\"\"\n",
        ">>> torch.Size([32])\n",
        "    # 1d: [batch_size] \n",
        "    # use for target labels or predictions.\n",
        ">>> torch.Size([12, 256])\n",
        "    # 2d: [batch_size, num_features (aka: C * H * W)]\n",
        "    # use for as nn.Linear() input.\n",
        ">>> torch.Size([10, 1, 2048])\n",
        "    # 3d: [batch_size, channels, num_features (aka: H * W)]\n",
        "    # when used as nn.Conv1d() input.\n",
        "    # (but [seq_len, batch_size, num_features]\n",
        "    # if feeding an RNN).\n",
        ">>> torch.Size([16, 3, 28, 28])\n",
        "    # 4d: [batch_size, channels, height, width]\n",
        "    # use for as nn.Conv2d() input.\n",
        ">>>  torch.Size([32, 1, 5, 15, 15])\n",
        "    # 5D: [batch_size, channels, depth, height, width]\n",
        "    # use for as nn.Conv3d() input.\n",
        "```    \n",
        "\n",
        "A neat method to make your tensors ready for the linear layer,  \n",
        "```\n",
        "Use view() to change your tensor’s dimensions.\n",
        "\n",
        "image = image.view(batch_size, -1)\n",
        "\n",
        "You supply your batch_size as the first number, and then “-1” basically tells Pytorch, “you figure out this other number for me… please.” \n",
        "Your tensor will now feed properly into any linear layer.\n",
        "```\n",
        "\n",
        "[Incredible Tutorial on PyTorch Layer Dimensions.](https://towardsdatascience.com/pytorch-layer-dimensions-what-sizes-should-they-be-and-why-4265a41e01fd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouQTXZetn53I",
        "colab_type": "text"
      },
      "source": [
        "Before we start,  \n",
        "1. What is the shape (dimensions) of our images?  \n",
        "2. What is the size of our batch? \n",
        "3. How many _'channels'_ are there in our images? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-McCK6u3WnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn # nn module contains all the layers \n",
        "import torch.nn.functional as F # same as nn, but a little different "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtUDongrrJlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our CNN based neural architecture \n",
        "# Let's build a simple one with only Convolutional, Linear \n",
        "# and dropout layers\n",
        "class MNISTModel1(nn.Module):\n",
        "    # Here we define the neural architecture \n",
        "    def __init__(self):\n",
        "        super(MNISTModel1, self).__init__() # Initialize the nn module \n",
        "        \n",
        "        # Convolutional Layers\n",
        "        # What shape/dimensions the first layer is going to see? \n",
        "        # Do we need to have some padding for a kernel_size = 3?  \n",
        "        # Input Features = 1 x 28 x 28\n",
        "        # Output Features = ???\n",
        "        # Shape of a Convolutional Layer = (W - K + 2P)\n",
        "        #                                  ------------ + 1\n",
        "        #                                       S\n",
        "        # where, \n",
        "        #       W = Width/Height of previous layer = 28\n",
        "        #       K = Filter Size = 3\n",
        "        #       P = Padding = 0\n",
        "        #       S = Stride = 1(default)\n",
        "        # Therefore, \n",
        "        #           if padding = 0\n",
        "        #           Output Shape = ((28 - 3 + 2*0)/1)+1 = 26 \n",
        "        # We want the dimensions to stay the same so that there is no \n",
        "        # loss of information when performing the convolution. \n",
        "        # Hence, \n",
        "        #       if padding = 1\n",
        "        #       Output Shape = ((28 - 3 + 2*1)/1)+1 = 28\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, \\\n",
        "                               stride=1, padding=1) # Output Features = 8 x 28 x 28  \n",
        "        # Input Features = 8 x 28 x 28\n",
        "        # Output Features = 16 x 28 x 28 | ((28 - 3 + 2*1)/1)+1 = 28\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, \\\n",
        "                               stride=1, padding=1)\n",
        "\n",
        "        # Linear Layers \n",
        "        # What shape the first linear layer is going see?\n",
        "        # What are the total number of features given out by conv2?\n",
        "        # Features = 16 x 28 x 28 = 12544\n",
        "        # Therefore,           \n",
        "        self.linear1 = nn.Linear(in_features=12544, out_features=256)\n",
        "        self.linear2 = nn.Linear(in_features=256, out_features=64)\n",
        "        # Last linear layer should output 10 features as we are \n",
        "        # Classifying the images in 10 categories \n",
        "        self.linear3 = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "        # Dropout \n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "\n",
        "    # Here we define the 'forward behaviour' of our neural architecture \n",
        "    def forward(self, image_batch):\n",
        "        # This is also the place where we add ACTIVATION functions \n",
        "        image_batch = F.relu(input=self.conv1(image_batch))          \n",
        "        image_batch = F.relu(input=self.conv2(image_batch))  \n",
        "        \n",
        "        # Remember that when passing image_batch through the Linear layers, \n",
        "        # PyTorch expects: \n",
        "        # >>> torch.Size([12, 256]) -> example values \n",
        "            # 2d: [batch_size, num_features (aka: C * H * W)]\n",
        "            # use for nn.Linear() input.   \n",
        "        # Therefore, we need to 'flatten' image_batch\n",
        "        # image_batch = image_batch.view(batch_size, -1) --> batch size ???\n",
        "        flat_image_batch = image_batch.view(image_batch.shape[0], -1)\n",
        "        flat_image_batch = F.relu(input=self.linear1(flat_image_batch))\n",
        "        # Let's add the dropout too \n",
        "        flat_image_batch = self.dropout(F.relu(input=self.linear2(flat_image_batch)))\n",
        "        # Final Layer of the network \n",
        "        flat_image_batch = F.relu(input=self.linear3(flat_image_batch))\n",
        "        # The output from the final layer is a tensor with 10 'logits'\n",
        "        return flat_image_batch               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEPNIgRiS9FN",
        "colab_type": "text"
      },
      "source": [
        "Now that we have defined our model, is there a way we can peep inside to see  \n",
        "what is going on and that if everything is alright?  \n",
        "\n",
        "Say hello to _**[torchsummary !!!](https://github.com/sksq96/pytorch-summary)**_ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHTtCrNxQ_X7",
        "colab_type": "code",
        "outputId": "32026c65-2169-4531-e431-56db28f1f0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's install torchsummary and do some cool stuff \n",
        "!pip install torchsummary # https://github.com/sksq96/pytorch-summary "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NylWMGTf1QbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtUFlNAd5lhN",
        "colab_type": "code",
        "outputId": "2fbd5cc6-72e2-415c-bf26-f3081b35ecb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# We can make the use of torchsummary library here to figure \n",
        "# if we have done something wrong \n",
        "\n",
        "# But first we need to tell PyTorch where to 'keep' the model \n",
        "# On GPU or on CPU \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "print('The model will run on', device)\n",
        "\n",
        "# Initialize the model \n",
        "mnist1 = MNISTModel1().to(device)\n",
        "summary(model=mnist1, input_size=(1, 28, 28), batch_size=20) # Summarize"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model will run on cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [20, 8, 28, 28]              80\n",
            "            Conv2d-2           [20, 16, 28, 28]           1,168\n",
            "            Linear-3                  [20, 256]       3,211,520\n",
            "            Linear-4                   [20, 64]          16,448\n",
            "           Dropout-5                   [20, 64]               0\n",
            "            Linear-6                   [20, 10]             650\n",
            "================================================================\n",
            "Total params: 3,229,866\n",
            "Trainable params: 3,229,866\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 2.93\n",
            "Params size (MB): 12.32\n",
            "Estimated Total Size (MB): 15.31\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyTvkdq3gqHM",
        "colab_type": "text"
      },
      "source": [
        "That was a lot of work.....Whew!  \n",
        "\n",
        "_***Q: Isn't there an 'easier' way to define the Model in 2020?***_  \n",
        "A: _**Yes, absolutely!**_  \n",
        "Say hello to the _**[torchlayers library !!!](https://github.com/szymonmaszke/torchlayers)**_  \n",
        "With torchlayers, the above code will be reduced to about 7-8 lines!  \n",
        "But unfortunately, [torchlayers requires Python 3.7](https://github.com/szymonmaszke/torchlayers/issues/5) and above. Colab only  \n",
        "supports Python 3.6.x. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YljS2tiRlHql",
        "colab_type": "text"
      },
      "source": [
        "With our model definition complete, it is time to train! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f08VsPbPn5bO",
        "colab_type": "text"
      },
      "source": [
        "### 5. Train a PyTorch Model in 2020  \n",
        "\n",
        "PyTorch is infamous among newcomers for it's _'training loops'_.  \n",
        "They can be long and at times a little confusing too. However, most of them   \n",
        "are similar and writing training loops simply turns out to be a boring and repetitive  \n",
        "exercise.  \n",
        "\n",
        "Q: _**This is 2020.**_ Is there a better way?  \n",
        "A: _**Yes, absolutely!**_  \n",
        "Say hello to _**[Poutyne !!!](https://poutyne.org/index.html)**_   \n",
        "\n",
        "\n",
        "Thanks to _Poutyne_, writing training loops in PyTorch is _**FUN !!!**_  \n",
        "\n",
        "PS - Poutyne is pronounced as Poutine or Pu-tin.  \n",
        "![Poutyne](https://drive.google.com/uc?id=142xYy_mJoPSk97SDicvn9zRNxHMpXDxz \"You think loops are boring?!?!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gpy_1cRZ6gV",
        "colab_type": "code",
        "outputId": "9a54a976-c513-49b3-8a8b-73c45308c4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Install Poutyne \n",
        "!pip install poutyne "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting poutyne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/83/6beb7cc2206e429342fa6385f92e1eccf1d2af8f4cbcdc5e7402cf65a5c5/Poutyne-0.7.2-py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from poutyne) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from poutyne) (1.18.2)\n",
            "Installing collected packages: poutyne\n",
            "Successfully installed poutyne-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnHdjqkhdzLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from poutyne.framework import Model # The core datastructure of poutyne \n",
        "                                    # https://poutyne.org/model.html\n",
        "from poutyne.framework import Callback # We will see it in action in a little while \n",
        "                                       # https://poutyne.org/callbacks.html# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVhp0yEiFfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim # Optimizer: we need it to train our network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EwMBpBtKE7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A pouytne training loop\n",
        "\n",
        "# A few hyperparamters for the training loop \n",
        "learning_rate = 0.1\n",
        "epochs = 3\n",
        "\n",
        "def poutyne_train(pytorch_model):\n",
        "    \n",
        "    # Select the optimizer and the loss function \n",
        "    optimizer = optim.SGD(pytorch_model.parameters(), lr=learning_rate)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    # Poutyne Model\n",
        "    model = Model(pytorch_model, optimizer, loss_function, batch_metrics=['accuracy'])\n",
        "    # Send the 'Poutyne model' on GPU/CPU whichever is available \n",
        "    model.to(device)\n",
        "    # Train\n",
        "    model.fit_generator(train_loader, valid_loader, epochs=epochs)\n",
        "    # Test\n",
        "    test_loss, test_acc = model.evaluate_generator(test_loader)\n",
        "    print(f'Test:\\n\\tLoss: {test_loss: .3f}\\n\\tAccuracy: {test_acc: .3f}')\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_znXT5djwzeY",
        "colab_type": "code",
        "outputId": "e3292dd0-92c2-4ae0-b885-503146ca14f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Let's start the training guys!!! \n",
        "poutyne_train(mnist1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3 35.42s Step 2400/2400: loss: 0.319735, acc: 90.016667, val_loss: 0.096412, val_acc: 97.183333\n",
            "Epoch 2/3 35.28s Step 2400/2400: loss: 0.079684, acc: 97.760417, val_loss: 0.068129, val_acc: 98.083333\n",
            "Epoch 3/3 34.94s Step 2400/2400: loss: 0.048999, acc: 98.589583, val_loss: 0.062555, val_acc: 98.183333\n",
            "Test:\n",
            "\tLoss:  0.047\n",
            "\tAccuracy:  98.440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqforBpLr0dk",
        "colab_type": "text"
      },
      "source": [
        "_**CONGRATULATIONS !!! You just trained your first(?) CNN Model!**_   \n",
        "The accuracy looks pretty decent as well! \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hakTX49k5wnW",
        "colab_type": "text"
      },
      "source": [
        "### 6. Understanding Overfitting \n",
        "Before we move any further we need to understand the concept of _**Overfitting**_  \n",
        "in Machine Learning models.  \n",
        "What is _**overfitting?**_  \n",
        "![Fitting Examples](https://drive.google.com/uc?id=1gFOa5I24S7XDDep4WaVMIoivh9JvIp1Y \"https://www.curiousily.com/posts/hackers-guide-to-fixing-underfitting-and-overfitting-models/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnE0htQzVRAs",
        "colab_type": "text"
      },
      "source": [
        "We are always looking to ensure that our models have a low bias with a low  \n",
        "variance.  \n",
        "However, if we train for too long (too many epochs) our model will start to  \n",
        "overfit.  \n",
        "\n",
        "How do we identify that the model has started overfitting?  \n",
        "![Overfitting](https://drive.google.com/uc?id=1q02q0ge0jldHJm8P_Hq6ECeIvaSlcc36 \"https://mlexplained.com/2018/04/24/overfitting-isnt-simple-overfitting-re-explained-with-priors-biases-and-no-free-lunch/\")  \n",
        "Dotted vertical line is where we should either stop training the model (also  \n",
        "known as _**Early Stopping**_) or we should have some logic in the training  \n",
        "loop that _'saves'_ the model around that time while the training still  \n",
        "continues. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6qwm4NIZQNf",
        "colab_type": "text"
      },
      "source": [
        "Our model will also overfit if it is too complex.  \n",
        "For example (y-axis is different),  \n",
        "![Complex Model](https://drive.google.com/uc?id=1vWHgknPrbXEQczdKMliB0RyVgYld3cGa \"https://medium.com/@george.drakos62/cross-validation-70289113a072\")  \n",
        "\n",
        "<br/>Early stopping can save the day!  \n",
        "![alt text](https://drive.google.com/uc?id=1HnBFMWZGHy0UFMUICKU25qBiB-4_G0Xn \"https://www.jeremyjordan.me/deep-neural-networks-preventing-overfitting/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhvAC7xGapnU",
        "colab_type": "text"
      },
      "source": [
        "A really nice matrix to identify if we are overfitting:  \n",
        "![Overfitting Matrix](https://drive.google.com/uc?id=19bFHepjNgQ9kpqmQdMEW4lDJ-qXi5WF8 \"https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42\")  \n",
        "While preparing the above matrix, the author has considered only two sets,  \n",
        "training and testing (kinda Deep Learning _faux pass_!). Since we have a  \n",
        "validation set as well, replace the word _**'Testing'**_ with  \n",
        "_**'Validation'**_. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qlOIi5RaeVI",
        "colab_type": "text"
      },
      "source": [
        "How can we avoid _**Overfitting**_?  \n",
        "1. Use a simpler model (less layers)  \n",
        "2. Use _Dropout_ \n",
        "3. Get more training data (if possible) \n",
        "4. Augment the data and add noise  \n",
        "5. Early Stopping  \n",
        "\n",
        "PS - Not an exhaustive list AT ALL.  \n",
        "\n",
        "<br/>Can we write a better training loop now? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10dxUCy3iR0A",
        "colab_type": "text"
      },
      "source": [
        "### 8. A Better Training Loop  \n",
        "We combine our knowledge of Early Stopping and saving the model at the right  \n",
        "time during training to write a better _Training Loop_.  \n",
        "\n",
        "We use [Callbacks](https://poutyne.org/callbacks.html# \"Click to visit link\") in Poutyne to incorporate Early Stopping and saving the model after every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLajWBECiXsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from poutyne.framework import ModelCheckpoint # Saves trained model during training\n",
        "                                              # https://poutyne.org/callbacks.html#checkpointing\n",
        "from poutyne.framework import EarlyStopping # You know what it does! ;) \n",
        "                                            # https://poutyne.org/callbacks.html#poutyne.framework.callbacks.EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icK1WbNHr-ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A better pouytne training loop\n",
        "# Turn the GPU ON\n",
        "\n",
        "# A few hyperparamters for the training loop \n",
        "learning_rate = 0.1\n",
        "epochs = 10 # let's train for more epochs to see the callbacks in action\n",
        "\n",
        "def better_poutyne_train(model_name, pytorch_model):\n",
        "    \n",
        "    callbacks = [\n",
        "    # Save the latest weights \n",
        "    ModelCheckpoint(model_name + '_last_epoch.ckpt', \\\n",
        "                    temporary_filename='last_epoch.ckpt.tmp'),\n",
        "    # EarlyStopping\n",
        "    EarlyStopping(monitor='val_acc', patience=0, verbose=True, mode='max')\n",
        "    ]\n",
        "    \n",
        "    # Select the optimizer and the loss function \n",
        "    optimizer = optim.SGD(pytorch_model.parameters(), lr=learning_rate)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    # Poutyne Model\n",
        "    model = Model(pytorch_model, optimizer, loss_function, batch_metrics=['accuracy'])\n",
        "    # Send the 'Poutyne model' on GPU/CPU whichever is available \n",
        "    model.to(device)\n",
        "    # Train\n",
        "    model.fit_generator(train_loader, valid_loader, epochs=epochs, callbacks=callbacks)\n",
        "    # Test\n",
        "    test_loss, test_acc = model.evaluate_generator(test_loader)\n",
        "    print(f'Test:\\n\\tLoss: {test_loss: .3f}\\n\\tAccuracy: {test_acc: .3f}')\n",
        "\n",
        "    return None "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffcjuFHa5v75",
        "colab_type": "code",
        "outputId": "6873b91d-00d3-4d3d-a4d2-fe18e729737a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# Let's initialize a new CNN Model just like before \n",
        "mnist2 = MNISTModel1().to(device)\n",
        "summary(model=mnist2, input_size=(1, 28, 28), batch_size=20) # Summarize"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [20, 8, 28, 28]              80\n",
            "            Conv2d-2           [20, 16, 28, 28]           1,168\n",
            "            Linear-3                  [20, 256]       3,211,520\n",
            "            Linear-4                   [20, 64]          16,448\n",
            "           Dropout-5                   [20, 64]               0\n",
            "            Linear-6                   [20, 10]             650\n",
            "================================================================\n",
            "Total params: 3,229,866\n",
            "Trainable params: 3,229,866\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 2.93\n",
            "Params size (MB): 12.32\n",
            "Estimated Total Size (MB): 15.31\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTWPxL4Y6Avb",
        "colab_type": "code",
        "outputId": "698901bc-d342-42d6-9c40-fdac7df67532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Time to train in a better way!.....takes about 120secs on GPU \n",
        "# Make sure to Turn the GPU ON\n",
        "better_poutyne_train(model_name='mnist2', pytorch_model=mnist2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 35.84s Step 2400/2400: loss: 0.349615, acc: 89.410417, val_loss: 0.097567, val_acc: 97.050000\n",
            "Epoch 2/10 35.07s Step 2400/2400: loss: 0.084915, acc: 97.591667, val_loss: 0.057187, val_acc: 98.250000\n",
            "Epoch 3/10 34.99s Step 2400/2400: loss: 0.051142, acc: 98.481250, val_loss: 0.067907, val_acc: 97.941667\n",
            "Epoch 4/10 35.47s Step 2400/2400: loss: 0.035583, acc: 98.897917, val_loss: 0.065921, val_acc: 98.083333\n",
            "Epoch 00005: early stopping\n",
            "Test:\n",
            "\tLoss:  0.055\n",
            "\tAccuracy:  98.310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us0ZQ7nqBGUk",
        "colab_type": "text"
      },
      "source": [
        "Nice! But you showed us those fancy graphs while talking about early stopping.  \n",
        "_**Where are those graphs now?!**_  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYsQWympCOuv",
        "colab_type": "text"
      },
      "source": [
        "###9. A Fancy Training Loop  \n",
        "\n",
        "When it comes to productivity enhancing libraries in the PyTorch ecosystem  \n",
        "Poutyne is not alone.  \n",
        "Say hello to [LiveLossPlot !!!](https://github.com/stared/livelossplot \"Click to visit Github Repository\")  \n",
        "\n",
        "Best part is the fact that LiveLossPlot and Poutyne are compatible with each  \n",
        "other! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiu2yYMU6hYX",
        "colab_type": "code",
        "outputId": "fec3d34f-8de7-41d7-8159-c0550afb322d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!pip install livelossplot "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/e4/a7884b57113dfe84d3565418820feae7a20964438beb1088b2b08820ad94/livelossplot-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.18.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (46.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib; python_version >= \"3.6\"->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.1.9)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlPkpKsTsfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from livelossplot import PlotLossesPoutyne # This module talks with Poutyne"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLpRKgNOGWFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A fancy pouytne training loop\n",
        "# Turn the GPU ON\n",
        "\n",
        "# A few hyperparamters for the training loop \n",
        "learning_rate = 0.1\n",
        "epochs = 10 # let's train for more epochs to see the callbacks in action\n",
        "\n",
        "def fancy_poutyne_train(model_name, pytorch_model):\n",
        "    \n",
        "    # setting up the livelossplot callback\n",
        "    plotlosses = PlotLossesPoutyne()\n",
        "\n",
        "    callbacks = [\n",
        "    # Save the latest weights \n",
        "    ModelCheckpoint(model_name + '_last_epoch.ckpt', \\\n",
        "                    temporary_filename='last_epoch.ckpt.tmp'),\n",
        "    # EarlyStopping\n",
        "    EarlyStopping(monitor='val_acc', patience=0, verbose=True, mode='max'),\n",
        "    # Adding the LiveLossPlot Callback\n",
        "    plotlosses\n",
        "    ]\n",
        "    \n",
        "    # Select the optimizer and the loss function \n",
        "    optimizer = optim.SGD(pytorch_model.parameters(), lr=learning_rate)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    # Poutyne Model\n",
        "    model = Model(pytorch_model, optimizer, loss_function, batch_metrics=['accuracy'])\n",
        "    # Send the 'Poutyne model' on GPU/CPU whichever is available \n",
        "    model.to(device)\n",
        "    # Train\n",
        "    model.fit_generator(train_loader, valid_loader, epochs=epochs, callbacks=callbacks)\n",
        "    # Test\n",
        "    test_loss, test_acc = model.evaluate_generator(test_loader)\n",
        "    print(f'Test:\\n\\tLoss: {test_loss: .3f}\\n\\tAccuracy: {test_acc: .3f}')\n",
        "\n",
        "    return None "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj9sG_AUUShG",
        "colab_type": "code",
        "outputId": "83ca8a1a-b0ee-461f-a0a2-3107ae905d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# Yet another CNN Model \n",
        "mnist3 = MNISTModel1().to(device)\n",
        "summary(model=mnist3, input_size=(1, 28, 28), batch_size=20) # Summarize"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [20, 8, 28, 28]              80\n",
            "            Conv2d-2           [20, 16, 28, 28]           1,168\n",
            "            Linear-3                  [20, 256]       3,211,520\n",
            "            Linear-4                   [20, 64]          16,448\n",
            "           Dropout-5                   [20, 64]               0\n",
            "            Linear-6                   [20, 10]             650\n",
            "================================================================\n",
            "Total params: 3,229,866\n",
            "Trainable params: 3,229,866\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 2.93\n",
            "Params size (MB): 12.32\n",
            "Estimated Total Size (MB): 15.31\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwA8L0XWUbVI",
        "colab_type": "code",
        "outputId": "62a1f3fe-38a6-46fb-e1cd-f2f3d63130a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# Let the Fancy training loop start! \n",
        "# Make sure to Turn the GPU ON\n",
        "fancy_poutyne_train(model_name='mnist3', pytorch_model=mnist3)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAE1CAYAAAD6akEFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkQmigCUiIiIiIjJBFLBEREREREQmyP8HVo/0RDTtp/IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy\n",
            "\ttraining         \t (min:   88.340, max:   99.650, cur:   99.650)\n",
            "\tvalidation       \t (min:   96.733, max:   98.508, cur:   98.508)\n",
            "Loss\n",
            "\ttraining         \t (min:    0.011, max:    0.379, cur:    0.011)\n",
            "\tvalidation       \t (min:    0.062, max:    0.109, cur:    0.068)\n",
            "Epoch 00008: early stopping\n",
            "Test:\n",
            "\tLoss:  0.054\n",
            "\tAccuracy:  98.700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxpV5o0Z-b3G",
        "colab_type": "text"
      },
      "source": [
        "Thanks to LiveLossPlot, we can see all the fancy graphs now!  \n",
        "\n",
        "_**You can now do a little experiment and see for yourself how the model starts  \n",
        "to overfit. Simply remove the Early Stopping callback from the training loop.**_\n",
        "\n",
        "<br/>You can see your model overfit even on such a simple dataset! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaXagq-rA8vL",
        "colab_type": "text"
      },
      "source": [
        "###10. Inference  \n",
        "We have a trained model in our hands now.  \n",
        "We would now like to write a simnple inference routine where we can enjoy  \n",
        "the predictions of our PyTorch Model! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpqrJYFZUpig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A rather straightforward inference routine \n",
        "\n",
        "def inference():\n",
        "    PATH = 'mnist3_last_epoch.ckpt' # Path to the saved model checkpoint\n",
        "\n",
        "    # Load the model \n",
        "    model = MNISTModel1().to('cpu') # Instantiate our PyTorch model \n",
        "    model.load_state_dict(torch.load(PATH)) # Load the saved model \n",
        "    # summary(model, (1, 28, 28), device='cpu') # Check if everything is correct \n",
        "\n",
        "    # Time to get some 'test_loader' data for our model \n",
        "    dataiter = iter(train_loader) # Get the whole batch \n",
        "    images, labels = dataiter.next() # Extract the images and their labels \n",
        "    label = labels[0] # The ground truth\n",
        "\n",
        "    # Images need a little bit of processing! \n",
        "    image = images[0] # Take the first image from the batch = 1 x 28 x 28\n",
        "    # Remember that our Model expects the first dimension as a 'batch size' \n",
        "    # Therefore, we add one extra dimension in the 'start.  \n",
        "    image = torch.unsqueeze(image, dim=0) # 1 x 1 x 28 x 28 (batch_size = 1)\n",
        "    print('\\nimage.shape =>', image.shape)\n",
        "\n",
        "    # Disable the autograd module \n",
        "    with torch.no_grad(): # no need to calculate the gradients as we are not training\n",
        "        # Make a forward-pass \n",
        "        output = model.forward(image)\n",
        "    \n",
        "    # Our model outputs 'logits', we need to transform it into class probabilities. \n",
        "    # https://discuss.pytorch.org/t/how-to-extract-probabilities/2720/12\n",
        "    # To transform logits, we need to use the 'Softmax' function\n",
        "    # https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d\n",
        "    # Therefore,  \n",
        "    class_probabilities = F.softmax(output, dim=1).numpy().squeeze()\n",
        "    print('\\nClass Probabilities ==>', class_probabilities)\n",
        "    for i, proba in enumerate(class_probabilities):\n",
        "        print(f'Class \\t{i}\\t Probability \\t{100*proba:.2f}%')\n",
        "\n",
        "    # A very Fancy way to showcase the results \n",
        "    # Create a figure with two axes, ax1 and ax2\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2) # Subplot with 2 columns\n",
        "    # ax1 holds the image from the test dataset\n",
        "    ax1.imshow(image.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.set_title('Ground Truth ' + str(label.numpy()))\n",
        "    # ax2 holds a horizontal bar chart containing class_probabilities \n",
        "    ax2.barh(np.arange(10), class_probabilities)\n",
        "    ax2.set_aspect(0.1) # aspect ratio of ax2, else it will get too big\n",
        "    ax2.set_yticks(np.arange(10)) # 10 ticks on the y-axis for 10 classes\n",
        "    ax2.set_yticklabels(np.arange(10)) # set the ticklabels from 0 to 9\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1) # probability can't be over 1, hence set limit to 1.1\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enklrq5uH3qi",
        "colab_type": "code",
        "outputId": "f9297d9f-7187-439e-ecce-f63eaea84848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "inference() "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "image.shape => torch.Size([1, 1, 28, 28])\n",
            "\n",
            "Class Probabilities ==> [1.08e-08 2.75e-05 1.00e+00 2.00e-06 1.42e-08 1.08e-08 1.08e-08 4.59e-07 1.08e-08 1.08e-08]\n",
            "Class \t0\t Probability \t0.00%\n",
            "Class \t1\t Probability \t0.00%\n",
            "Class \t2\t Probability \t100.00%\n",
            "Class \t3\t Probability \t0.00%\n",
            "Class \t4\t Probability \t0.00%\n",
            "Class \t5\t Probability \t0.00%\n",
            "Class \t6\t Probability \t0.00%\n",
            "Class \t7\t Probability \t0.00%\n",
            "Class \t8\t Probability \t0.00%\n",
            "Class \t9\t Probability \t0.00%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADHCAYAAAAAoQhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1qacwM3M2tT/B0sSzReOavtVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKN3ZR_Gh22S",
        "colab_type": "text"
      },
      "source": [
        "###11. Thank You!  \n",
        "Guys, thank you so much for being with me through this webinar.  \n",
        "I would like to thank each and every one of you out there!  \n",
        "\n",
        "I will be really happy to connect with you all on LinkedIN, feel free to drop  \n",
        "in a connection request. \n",
        " \n",
        "https://www.linkedin.com/in/pranjall/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2lXpTfRk7JO",
        "colab_type": "text"
      },
      "source": [
        "###12. BONUS! \n",
        "\n",
        "I will be adding some bonus content in this Notebook in the coming week.  \n",
        "Namely,  \n",
        "1. Transfer Learning  \n",
        "2. Visualizing computation graphs of your custom model  \n",
        "3. Visualizing what your CNN layer is looking at (it is amazing, trust me!)  \n",
        "\n",
        "Consider _**starring**_ this repository on Github if you liked this webinar  \n",
        "and want to get the bonus material coming later in this week.  \n",
        "A lot of my peers at Udacity have loved the content in this repo, checkout the  \n",
        "`Introduction to Neural Networks` folder.  \n",
        "\n",
        "I plan to keep uploading/updating the content of all of my future webinars in   \n",
        "this repository. \n",
        "\n",
        "https://github.com/pranjalchaubey/Deep-Learning-Notes  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KbNEwlOmLq1",
        "colab_type": "text"
      },
      "source": [
        "_**Wishing you guys all the best in your Deep Learning journey with PyTorch!**_ "
      ]
    }
  ]
}